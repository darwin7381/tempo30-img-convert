"""é¢¨æ ¼è½‰æ›æ¨¡çµ„ - å‘é‡æ’ç•«é¢¨æ ¼ï¼ˆåŠå¯«å¯¦ä¼æ¥­é ­åƒã€è³½ç’ç’è‘—è‰²ã€éš¨æ©Ÿé«˜å…‰ã€é€æ˜èƒŒæ™¯ï¼‰

å„ªåŒ–ç‰ˆæœ¬:
- åˆä½µåœ–ç‰‡é¡å‹èˆ‡èº«é«”ç¯„åœæª¢æ¸¬ç‚ºå–®ä¸€ API å‘¼å«ï¼ˆæ¸›å°‘ 33% API é…é¡æ¶ˆè€—ï¼‰
- åŠ å…¥ API é…é¡éŒ¯èª¤è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
- ä½¿ç”¨é›†ä¸­å¼è¨­å®šç®¡ç†
"""

import os
import io
import math
import base64
import json
import re
import requests
from PIL import Image, ImageDraw, ImageFilter
from google import genai
from google.genai import types
from dotenv import load_dotenv
import numpy as np
from scipy import ndimage

from .config import STYLE_CONFIG, API_CONFIG
from .utils import retry_on_quota_error, prepare_image_for_api
from .prompts import get_style_prompt, ANALYZE_PROMPT


class StyleConverter:
    """é¢¨æ ¼è½‰æ›å™¨ - å°‡ç…§ç‰‡è½‰ç‚ºå‘é‡æ’ç•«é¢¨æ ¼ï¼ˆåŠå¯«å¯¦ä¼æ¥­é ­åƒã€è³½ç’ç’œè‘—è‰²ã€éš¨æ©Ÿé«˜å…‰ã€é€æ˜èƒŒæ™¯ï¼Œèƒ¸éƒ¨ä»¥ä¸Šè£å‰ªï¼Œçµ±ä¸€å°ºå¯¸ï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
        load_dotenv()
        if API_CONFIG.use_gateway:
            # ä½¿ç”¨ API ç¶²é—œï¼ˆOpenRouterï¼‰
            self.api_key = API_CONFIG.api_key
            self.api_url = API_CONFIG.api_gateway_url  # å·²ç¶“åŒ…å«å®Œæ•´è·¯å¾‘
            self.client = None
        else:
            # ç›´æ¥ä½¿ç”¨ Gemini SDK
            self.client = genai.Client(api_key=API_CONFIG.api_key)
            self.api_key = None
            self.api_url = None
    
    def _call_openrouter_api(self, prompt: str, image: Image.Image = None, response_format: str = "text") -> dict:
        """
        é€šé OpenRouter API ç¶²é—œèª¿ç”¨æ¨¡å‹
        
        Args:
            prompt: æ–‡å­—æç¤º
            image: å¯é¸çš„åœ–ç‰‡
            response_format: "text" æˆ– "image"
            
        Returns:
            API å›æ‡‰çš„å­—å…¸
        """
        _, img_bytes = prepare_image_for_api(image) if image else (None, None)
        img_base64 = base64.b64encode(img_bytes).decode('utf-8') if img_bytes else None
        
        # æ§‹å»ºæ¶ˆæ¯å…§å®¹
        content = [{"type": "text", "text": prompt}]
        if img_base64:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{img_base64}"
                }
            })
        
        payload = {
            "model": API_CONFIG.model_text if response_format == "text" else API_CONFIG.model_image,
            "messages": [
                {
                    "role": "user",
                    "content": content
                }
            ]
        }
        
        headers = {
            "X-API-Key": self.api_key,  # è‡ªå®šç¾©ç¶²é—œçš„èªè­‰ key
            "Content-Type": "application/json",
            "HTTP-Referer": "https://blocktempo.ai",
            "X-Title": "Tempo Image Converter"
        }
        
        # å¦‚æœé…ç½®äº† OpenRouter API keyï¼Œä¹Ÿæ·»åŠ åˆ° header ä¸­
        openrouter_key = API_CONFIG.openrouter_api_key
        if openrouter_key:
            headers["Authorization"] = f"Bearer {openrouter_key}"
        
        response = requests.post(self.api_url, json=payload, headers=headers, timeout=120)
        response.raise_for_status()
        
        # èª¿è©¦ï¼šæ‰“å°éŸ¿æ‡‰ç‹€æ…‹å’Œå…§å®¹
        try:
            return response.json()
        except json.JSONDecodeError as e:
            print(f"âš ï¸ API å›æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„ JSON")
            print(f"âš ï¸ ç‹€æ…‹ç¢¼: {response.status_code}")
            print(f"âš ï¸ å›æ‡‰å…§å®¹ (å‰500å­—ç¬¦): {response.text[:500]}")
            print(f"âš ï¸ è«‹æ±‚ URL: {self.api_url}")
            print(f"âš ï¸ è«‹æ±‚ Headers: {headers}")
            raise ValueError(f"API å›æ‡‰æ ¼å¼éŒ¯èª¤: {e}")
    
    @retry_on_quota_error(max_retries=API_CONFIG.max_retries, base_delay=API_CONFIG.base_retry_delay)
    def analyze_image(self, image: Image.Image) -> dict:
        """
        åˆä½µæª¢æ¸¬ï¼šåŒæ™‚åˆ†æåœ–ç‰‡é¡å‹å’Œèº«é«”ç¯„åœï¼ˆå–®ä¸€ API å‘¼å«ï¼‰
        
        æ­¤æ–¹æ³•å°‡åŸæœ¬çš„ detect_image_type() å’Œ detect_body_extent() åˆä½µç‚ºä¸€æ¬¡ API å‘¼å«ï¼Œ
        æ¸›å°‘ 33% çš„ API é…é¡æ¶ˆè€—ã€‚
        
        Args:
            image: PIL Image ç‰©ä»¶
            
        Returns:
            dict: {
                "image_type": "photo" æˆ– "illustration",
                "body_extent": "head_only", "head_neck", "head_chest", æˆ– "full_body"
            }
        """
        prompt = ANALYZE_PROMPT
        
        try:
            if API_CONFIG.use_gateway:
                # ä½¿ç”¨ OpenRouter API ç¶²é—œ
                response = self._call_openrouter_api(prompt, image, response_format="text")
                result = response["choices"][0]["message"]["content"].strip().upper()
            else:
                # ä½¿ç”¨ Gemini SDKï¼ˆPrompt é †åºï¼šåœ–ç‰‡åœ¨å‰ï¼Œç¬¦åˆæœ€ä½³å¯¦è¸ï¼‰
                _, img_bytes = prepare_image_for_api(image)
                api_response = self.client.models.generate_content(
                    model=API_CONFIG.model_text,
                    contents=[
                        types.Part.from_bytes(
                            data=img_bytes,
                            mime_type="image/png"
                        ),
                        prompt  # Prompt åœ¨åœ–ç‰‡å¾Œé¢
                    ],
                    config=types.GenerateContentConfig(
                        response_modalities=['TEXT']
                    )
                )
                result = api_response.candidates[0].content.parts[0].text.strip().upper()
            
            # è§£æå›æ‡‰
            image_type = "photo"
            body_extent = "full_body"
            
            if "ILLUSTRATION" in result:
                image_type = "illustration"
            
            if "HEAD_ONLY" in result:
                body_extent = "head_only"
            elif "HEAD_NECK" in result:
                body_extent = "head_neck"
            elif "HEAD_CHEST" in result:
                body_extent = "head_chest"
            else:
                body_extent = "full_body"
            
            return {"image_type": image_type, "body_extent": body_extent}
            
        except Exception as e:
            print(f"âš ï¸ åœ–ç‰‡åˆ†æå¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼: {e}")
            return {"image_type": "photo", "body_extent": "full_body"}
    
    def detect_image_type(self, image: Image.Image) -> str:
        """
        æª¢æ¸¬åœ–ç‰‡é¡å‹ï¼ˆä¿ç•™å‘å¾Œç›¸å®¹æ€§ï¼Œå…§éƒ¨ä½¿ç”¨ analyze_imageï¼‰
        """
        return self.analyze_image(image)["image_type"]
    
    def detect_body_extent(self, image: Image.Image) -> str:
        """
        æª¢æ¸¬èº«é«”éƒ¨ä½ç¯„åœï¼ˆä¿ç•™å‘å¾Œç›¸å®¹æ€§ï¼Œå…§éƒ¨ä½¿ç”¨ analyze_imageï¼‰
        """
        return self.analyze_image(image)["body_extent"]
    
    def convert_to_grayscale(self, image: Image.Image) -> Image.Image:
        """
        å°‡åœ–ç‰‡è½‰æ›ç‚ºç°éšï¼ˆç”¨æ–¼æ’ç•«/å‘é‡åœ–ï¼‰
        
        Args:
            image: PIL Image ç‰©ä»¶
            
        Returns:
            ç°éšåœ–ç‰‡ (RGBA æ¨¡å¼)
        """
        if image.mode != "RGBA":
            image = image.convert("RGBA")
        
        # åˆ†é›¢é€šé“
        r, g, b, a = image.split()
        
        # è½‰æ›ç‚ºç°éš (ä½¿ç”¨æ¨™æº–äº®åº¦å…¬å¼)
        gray = Image.merge("RGB", (r, g, b)).convert("L")
        
        # é‡æ–°çµ„åˆç‚º RGBA
        result = Image.merge("RGBA", (gray, gray, gray, a))
        return result
    
    def convert_to_cartoon_illustration(self, image: Image.Image, body_extent: str = "head_chest") -> Image.Image:
        """
        å°‡ç…§ç‰‡è½‰æ›ç‚ºå‘é‡æ’ç•«é¢¨æ ¼
        
        Args:
            image: PIL Image ç‰©ä»¶
            body_extent: èº«é«”éƒ¨ä½ç¯„åœ ("head_only", "head_neck", "head_chest", "full_body")
            
        Returns:
            è½‰æ›å¾Œçš„æ’ç•«åœ–ç‰‡
        """
        # ä½¿ç”¨æ¨¡çµ„åŒ–çš„ Prompt æ¨¡æ¿ï¼ˆæ¸›å°‘ 66% Token æ¶ˆè€—ï¼‰
        prompt = get_style_prompt(body_extent)
        
        if API_CONFIG.use_gateway:
            # ä½¿ç”¨ OpenRouter API ç¶²é—œ
            # OpenRouter ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼ï¼Œä½†åœ–ç‰‡ç”Ÿæˆå¯èƒ½éœ€è¦ç‰¹æ®Šè™•ç†
            try:
                response = self._call_openrouter_api(prompt, image, response_format="image")
                
                # å˜—è©¦å¾å›æ‡‰ä¸­æå–åœ–ç‰‡
                # OpenRouter çš„åœ–ç‰‡å›æ‡‰å¯èƒ½åœ¨ä¸åŒä½ç½®
                if "choices" in response and len(response["choices"]) > 0:
                    choice = response["choices"][0]
                    
                    # æª¢æŸ¥ message.content æ˜¯å¦åŒ…å«åœ–ç‰‡
                    if "message" in choice:
                        content = choice["message"].get("content", "")
                        if isinstance(content, str):
                            # æª¢æŸ¥æ˜¯å¦æœ‰ base64 åœ–ç‰‡
                            base64_match = re.search(r'data:image/[^;]+;base64,([A-Za-z0-9+/=]+)', content)
                            if base64_match:
                                image_data = base64.b64decode(base64_match.group(1))
                                result_image = Image.open(io.BytesIO(image_data))
                                return result_image
                        elif isinstance(content, list):
                            # å¦‚æœ content æ˜¯åˆ—è¡¨ï¼ŒæŸ¥æ‰¾åœ–ç‰‡é …
                            for item in content:
                                if item.get("type") == "image_url":
                                    url = item.get("image_url", {}).get("url", "")
                                    if url.startswith("data:image"):
                                        base64_match = re.search(r'data:image/[^;]+;base64,([A-Za-z0-9+/=]+)', url)
                                        if base64_match:
                                            image_data = base64.b64decode(base64_match.group(1))
                                            result_image = Image.open(io.BytesIO(image_data))
                                            return result_image
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„åœ–ç‰‡æ•¸æ“š
                    if "image" in choice or "image_data" in choice:
                        image_data = choice.get("image") or choice.get("image_data")
                        if isinstance(image_data, str):
                            # å¦‚æœæ˜¯ base64 å­—ç¬¦ä¸²
                            if not image_data.startswith("data:"):
                                image_data = f"data:image/png;base64,{image_data}"
                            base64_match = re.search(r'data:image/[^;]+;base64,([A-Za-z0-9+/=]+)', image_data)
                            if base64_match:
                                image_bytes = base64.b64decode(base64_match.group(1))
                                result_image = Image.open(io.BytesIO(image_bytes))
                                return result_image
                
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°åœ–ç‰‡ï¼Œæ‰“å°å›æ‡‰ä»¥ä¾¿èª¿è©¦
                print(f"âš ï¸ OpenRouter API å›æ‡‰æ ¼å¼: {json.dumps(response, indent=2)[:500]}")
                raise ValueError("OpenRouter API å›æ‡‰ä¸­æœªæ‰¾åˆ°åœ–ç‰‡æ•¸æ“š")
            except Exception as e:
                print(f"âš ï¸ OpenRouter API èª¿ç”¨å¤±æ•—: {e}")
                if 'response' in locals():
                    print(f"âš ï¸ å›æ‡‰å…§å®¹: {json.dumps(response, indent=2)[:1000]}")
                raise
        else:
            # ä½¿ç”¨ Gemini SDK
            _, img_bytes = prepare_image_for_api(image)
            api_response = self.client.models.generate_content(
                model=API_CONFIG.model_image,
                contents=[
                    prompt,
                    types.Part.from_bytes(
                        data=img_bytes,
                        mime_type="image/png"
                    )
                ],
                config=types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE']
                )
            )
            
            # å¾å›æ‡‰ä¸­æå–åœ–ç‰‡
            for part in api_response.candidates[0].content.parts:
                if part.inline_data is not None:
                    image_data = part.inline_data.data
                    result_image = Image.open(io.BytesIO(image_data))
                    return result_image
            
            raise ValueError("Gemini API æœªè¿”å›åœ–ç‰‡")
    
    def make_white_transparent(self, image: Image.Image, threshold: int = 240) -> Image.Image:
        """
        å°‡ç™½è‰²èƒŒæ™¯è½‰ç‚ºé€æ˜ï¼ˆè™•ç†é‚Šç·£é€£é€šçš„ç™½è‰²å€åŸŸï¼Œä¸¦ä¿è­·äººç‰©å…§éƒ¨ï¼‰
        """
        if image.mode != "RGBA":
            image = image.convert("RGBA")
        
        data = np.array(image)
        height, width = data.shape[0], data.shape[1]
        
        # æ‰¾å‡ºæ¥è¿‘ç´”ç™½è‰²çš„åƒç´ ï¼ˆé™ä½é–¾å€¼ä»¥æ•æ‰æ›´å¤šç™½è‰²ï¼‰
        white_mask = (data[:, :, 0] > threshold) & \
                     (data[:, :, 1] > threshold) & \
                     (data[:, :, 2] > threshold)
        
        # ä½¿ç”¨é€£é€šå€åŸŸæ¨™è¨˜
        labeled, num_features = ndimage.label(white_mask)
        
        # æ‰¾å‡ºèˆ‡é‚Šç·£æ¥è§¸çš„æ¨™ç±¤
        edge_labels = set()
        edge_labels.update(labeled[0, :])
        edge_labels.update(labeled[-1, :])
        edge_labels.update(labeled[:, 0])
        edge_labels.update(labeled[:, -1])
        edge_labels.discard(0)
        
        # æ‰¾å‡ºéç™½è‰²å€åŸŸï¼ˆäººç‰©å€åŸŸï¼‰ï¼Œæé«˜é–¾å€¼ä¿è­·äº®éƒ¨è¡£ç‰©
        person_mask = (data[:, :, 0] < 245) | (data[:, :, 1] < 245) | (data[:, :, 2] < 245)
        
        # å°äººç‰©é®ç½©é€²è¡Œè†¨è„¹ï¼Œå‰µå»ºä¿è­·å€åŸŸ
        if np.any(person_mask):
            person_mask_expanded = ndimage.binary_dilation(person_mask, structure=np.ones((20, 20)))
        else:
            person_mask_expanded = np.zeros((height, width), dtype=bool)
        
        # è™•ç†æ¯å€‹èˆ‡é‚Šç·£ç›¸é€£çš„ç™½è‰²å€åŸŸ
        bg_mask = np.zeros((height, width), dtype=bool)
        for label in edge_labels:
            region_mask = (labeled == label)
            
            # æª¢æŸ¥é€™å€‹å€åŸŸæ˜¯å¦ä¸»è¦åœ¨ä¿è­·å€åŸŸå¤–
            overlap = np.sum(region_mask & person_mask_expanded)
            total = np.sum(region_mask)
            
            # å¦‚æœé‡ç–Šå°æ–¼30%ï¼Œè¦–ç‚ºèƒŒæ™¯
            if total > 0 and overlap / total < 0.3:
                bg_mask = bg_mask | region_mask
        
        # å°‡èƒŒæ™¯è¨­ç‚ºé€æ˜
        data[bg_mask, 3] = 0
        
        return Image.fromarray(data, "RGBA")
    
    def add_white_outline(self, image: Image.Image, outline_width: int = 8) -> Image.Image:
        """
        ç‚ºåœ–ç‰‡æ·»åŠ ç™½è‰²ç²—ç·šæé‚Š
        
        Args:
            image: è¼¸å…¥åœ–ç‰‡ï¼ˆRGBA æ¨¡å¼ï¼‰
            outline_width: æé‚Šå¯¬åº¦ï¼ˆåƒç´ ï¼‰
            
        Returns:
            æ·»åŠ æé‚Šå¾Œçš„åœ–ç‰‡
        """
        if image.mode != "RGBA":
            image = image.convert("RGBA")
        
        # ç²å– alpha é€šé“
        alpha = image.split()[3]
        
        # å‰µå»ºä¸€å€‹æ›´å¤§çš„ç•«å¸ƒä¾†å®¹ç´æé‚Š
        width, height = image.size
        new_width = width + outline_width * 2
        new_height = height + outline_width * 2
        
        # å‰µå»ºæ–°åœ–ç‰‡ï¼ˆé€æ˜èƒŒæ™¯ï¼‰
        result = Image.new("RGBA", (new_width, new_height), (0, 0, 0, 0))
        
        # å°‡åŸåœ–è²¼åˆ°ä¸­å¿ƒä½ç½®
        result.paste(image, (outline_width, outline_width), image)
        
        # ç²å–çµæœçš„ alpha é€šé“
        result_alpha = result.split()[3]
        
        # å° alpha é€šé“é€²è¡Œè†¨è„¹ä¾†å‰µå»ºæé‚Š
        alpha_array = np.array(result_alpha)
        
        # ä½¿ç”¨å¤šæ¬¡è†¨è„¹ä¾†å‰µå»ºç²—ç·šæé‚Š
        for _ in range(outline_width):
            alpha_array = ndimage.binary_dilation(alpha_array, structure=np.ones((3, 3)))
        
        # å‰µå»ºæé‚Šé®ç½©ï¼ˆè†¨è„¹å¾Œçš„å€åŸŸæ¸›å»åŸå§‹å€åŸŸï¼‰
        original_alpha = np.array(result.split()[3])
        outline_mask = alpha_array & (~original_alpha.astype(bool))
        
        # å‰µå»ºç™½è‰²æé‚Š
        result_array = np.array(result)
        result_array[outline_mask, 0] = 255  # R
        result_array[outline_mask, 1] = 255  # G
        result_array[outline_mask, 2] = 255  # B
        result_array[outline_mask, 3] = 255  # A
        
        return Image.fromarray(result_array, "RGBA")
    
    def crop_horizontal_bottom(self, image: Image.Image) -> Image.Image:
        """
        å°‡åœ–ç‰‡åº•éƒ¨è£åˆ‡æˆæ°´å¹³ï¼ˆåœ¨æœ€çµ‚ç•«å¸ƒä¸Šæª¢æ¸¬äººç‰©åº•éƒ¨ï¼Œç„¶å¾Œæ°´å¹³è£åˆ‡ï¼‰
        
        Args:
            image: è¼¸å…¥åœ–ç‰‡ï¼ˆRGBA æ¨¡å¼ï¼Œæ‡‰è©²æ˜¯å·²ç¶“çµ±ä¸€å°ºå¯¸çš„ç•«å¸ƒï¼‰
            
        Returns:
            åº•éƒ¨æ°´å¹³è£åˆ‡å¾Œçš„åœ–ç‰‡
        """
        if image.mode != "RGBA":
            image = image.convert("RGBA")
        
        data = np.array(image)
        height, width = data.shape[0], data.shape[1]
        
        # ç²å–éé€æ˜å€åŸŸ
        alpha = data[:, :, 3]
        person_mask = alpha > 0
        
        if not np.any(person_mask):
            return image
        
        # æ‰¾å‡ºäººç‰©å€åŸŸ
        rows, cols = np.where(person_mask)
        if len(rows) == 0:
            return image
        
        # æ‰¾å‡ºäººç‰©å¯¬åº¦çš„ä¸­å¿ƒå€åŸŸï¼ˆèº«é«”éƒ¨åˆ†ï¼Œä¸åŒ…æ‹¬å´é‚Šçš„æ‰‹éƒ¨ï¼‰
        min_col = cols.min()
        max_col = cols.max()
        center_col = (min_col + max_col) // 2
        center_width = (max_col - min_col) // 3  # ä¸­å¿ƒ 1/3 å€åŸŸ
        
        # åœ¨ä¸­å¿ƒå€åŸŸæ‰¾å‡ºæœ€ä½é»ï¼ˆèº«é«”åº•éƒ¨ï¼‰
        center_region = (cols >= center_col - center_width) & (cols <= center_col + center_width)
        if np.any(center_region):
            body_bottom_row = rows[center_region].max()
        else:
            body_bottom_row = rows.max()
        
        # å°‡èº«é«”åº•éƒ¨ä»¥ä¸‹çš„æ‰€æœ‰å…§å®¹è¨­ç‚ºé€æ˜ï¼ˆæ°´å¹³è£åˆ‡ï¼‰
        # ç¢ºä¿åº•éƒ¨æ˜¯æ°´å¹³çš„
        if body_bottom_row < height - 1:
            data[body_bottom_row + 1:, :, 3] = 0
        
        return Image.fromarray(data, "RGBA")
    def normalize_size_and_position(
        self,
        image: Image.Image,
        target_size: tuple[int, int] = (1000, 1000),
        head_ratio: float = 0.35
    ) -> Image.Image:
        """
        çµ±ä¸€å°ºå¯¸å’Œä½ç½®ï¼Œå¢åŠ åŒè³ªæ€§ï¼ˆä¿ç•™å®Œæ•´äººç‰©ï¼Œä¸è£åˆ‡ä»»ä½•éƒ¨åˆ†ï¼‰
        
        Args:
            image: è¼¸å…¥åœ–ç‰‡ï¼ˆRGBA æ¨¡å¼ï¼‰
            target_size: ç›®æ¨™å°ºå¯¸ (width, height)
            head_ratio: é ­éƒ¨åœ¨ç•«é¢ä¸­çš„æ¯”ä¾‹ï¼ˆå¾é ‚éƒ¨é–‹å§‹ï¼‰
            
        Returns:
            çµ±ä¸€å°ºå¯¸å’Œä½ç½®å¾Œçš„åœ–ç‰‡
        """
        if image.mode != "RGBA":
            image = image.convert("RGBA")
        
        width, height = image.size
        target_width, target_height = target_size
        
        # ç²å–éé€æ˜å€åŸŸ
        alpha = np.array(image.split()[3])
        person_mask = alpha > 0
        
        if not np.any(person_mask):
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°äººç‰©ï¼Œç›´æ¥ç¸®æ”¾
            return image.resize(target_size, Image.Resampling.LANCZOS)
        
        # æ‰¾å‡ºäººç‰©å€åŸŸçš„é‚Šç•Œ
        rows, cols = np.where(person_mask)
        min_row, max_row = rows.min(), rows.max()
        min_col, max_col = cols.min(), cols.max()
        
        person_height = max_row - min_row
        person_width = max_col - min_col
        
        # ç‚ºäº†é¿å…è¢«è£åˆ‡ï¼Œå°é‚Šç•ŒåŠ ä¸Š 10% çš„ç·©è¡ï¼ˆå¢åŠ ç·©è¡ï¼‰
        padding_h = max(10, int(person_height * 0.1))
        padding_w = max(10, int(person_width * 0.1))
        min_row = max(0, min_row - padding_h)
        max_row = min(height - 1, max_row + padding_h)
        min_col = max(0, min_col - padding_w)
        max_col = min(width - 1, max_col + padding_w)
        person_height = max_row - min_row
        person_width = max_col - min_col
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼ˆç¢ºä¿äººç‰©å¤§å°ä¸€è‡´ï¼Œä¸åŒç…§ç‰‡çš„äººç‰©æ¯”ä¾‹ç›¸åŒï¼‰
        # å›ºå®šäººç‰©é«˜åº¦ç‚ºç›®æ¨™é«˜åº¦çš„ 70%ï¼ˆç¢ºä¿ä¸€è‡´æ€§ï¼‰
        # å›ºå®šäººç‰©å¯¬åº¦ç‚ºç›®æ¨™å¯¬åº¦çš„ 85%ï¼ˆç¢ºä¿ä¸€è‡´æ€§ï¼‰
        target_person_height = int(target_height * 0.70)
        target_person_width = int(target_width * 0.85)
        
        # è¨ˆç®—åŸºæ–¼é«˜åº¦å’Œå¯¬åº¦çš„ç¸®æ”¾æ¯”ä¾‹
        scale_height = target_person_height / person_height if person_height > 0 else 1.0
        scale_width = target_person_width / person_width if person_width > 0 else 1.0
        
        # ä½¿ç”¨è¼ƒå°çš„ç¸®æ”¾æ¯”ä¾‹ï¼Œç¢ºä¿å®Œæ•´ä¿ç•™äººç‰©ï¼ˆåŒ…æ‹¬æ‰‹éƒ¨å’Œå…©å´ï¼‰
        # é€™æ¨£å¯ä»¥ç¢ºä¿äººç‰©å¤§å°ä¸€è‡´ï¼Œä¸æœƒå› ç‚ºåŸå§‹åœ–ç‰‡å¤§å°ä¸åŒè€Œè®ŠåŒ–
        scale = min(scale_height, scale_width)
        
        # è¨ˆç®—éœ€è¦çš„é‚Šè·ï¼ˆå·¦å³å„ 5%ï¼‰
        side_margin = int(target_width * 0.05)
        
        # ç¸®æ”¾åœ–ç‰‡
        new_width = int(width * scale)
        new_height = int(height * scale)
        scaled_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # é‡æ–°è¨ˆç®—äººç‰©ä½ç½®ï¼ˆç¸®æ”¾å¾Œï¼‰
        scaled_alpha = np.array(scaled_image.split()[3])
        scaled_person_mask = scaled_alpha > 0
        if np.any(scaled_person_mask):
            scaled_rows, scaled_cols = np.where(scaled_person_mask)
            scaled_min_row = scaled_rows.min()
            scaled_max_row = scaled_rows.max()
            scaled_min_col = scaled_cols.min()
            scaled_max_col = scaled_cols.max()
            
            scaled_person_height = scaled_max_row - scaled_min_row
            scaled_person_width = scaled_max_col - scaled_min_col
        else:
            scaled_person_height = new_height
            scaled_person_width = new_width
            scaled_min_row = 0
            scaled_min_col = 0
            scaled_max_col = new_width
        
        # å‰µå»ºç›®æ¨™å°ºå¯¸çš„ç•«å¸ƒ
        result = Image.new("RGBA", target_size, (0, 0, 0, 0))
        
        # è¨ˆç®—ä½ç½®ï¼šç¢ºä¿äººç‰©å®Œæ•´é¡¯ç¤ºï¼Œå…©å´éƒ½æœ‰é‚Šè·
        # æ°´å¹³ï¼šè®“äººç‰©åœ¨ç•«å¸ƒä¸­å±…ä¸­ï¼Œç¢ºä¿æœ€å·¦å’Œæœ€å³éƒ½æœ‰é‚Šè·
        # è¨ˆç®—äººç‰©åœ¨ç¸®æ”¾å¾Œåœ–ç‰‡ä¸­çš„å¯¦éš›ä½ç½®
        person_left_in_scaled = scaled_min_col
        person_right_in_scaled = scaled_max_col
        person_width_in_scaled = person_right_in_scaled - person_left_in_scaled
        person_center_in_scaled = person_left_in_scaled + person_width_in_scaled / 2
        
        # è¨ˆç®—ç•«å¸ƒçš„ä¸­å¿ƒä½ç½®
        target_center_x = target_width / 2
        
        # è¨ˆç®— x_offsetï¼šè®“äººç‰©çš„ä¸­å¿ƒå°é½Šåˆ°ç•«å¸ƒä¸­å¿ƒ
        x_offset = int(target_center_x - person_center_in_scaled)
        
        # ç¢ºä¿äººç‰©å®Œæ•´é¡¯ç¤ºï¼ˆæª¢æŸ¥é‚Šç•Œï¼‰
        # å¦‚æœäººç‰©å¤ªå¯¬ï¼Œèª¿æ•´ä½ç½®ä»¥ç¢ºä¿ä¸è¶…å‡ºé‚Šç•Œ
        if x_offset + person_left_in_scaled < side_margin:
            # äººç‰©å·¦é‚Šè¶…å‡ºï¼Œèª¿æ•´åˆ°å·¦é‚Šè·
            x_offset = side_margin - person_left_in_scaled
        if x_offset + person_right_in_scaled > target_width - side_margin:
            # äººç‰©å³é‚Šè¶…å‡ºï¼Œèª¿æ•´åˆ°å³é‚Šè·
            x_offset = (target_width - side_margin) - person_right_in_scaled
        
        # å‚ç›´ï¼šé ­éƒ¨ä½ç½®å›ºå®šï¼ˆæ ¹æ“š head_ratioï¼‰
        head_top_y = int(target_height * head_ratio)
        y_offset = head_top_y - scaled_min_row
        
        # ç¢ºä¿å‚ç›´æ–¹å‘ä¸è¶…å‡º
        if y_offset < 0:
            y_offset = 0
        if y_offset + new_height > target_height:
            y_offset = target_height - new_height
        
        # è²¼ä¸Šåœ–ç‰‡ï¼ˆå®Œæ•´ä¿ç•™ï¼Œä¸è£åˆ‡ï¼‰
        result.paste(scaled_image, (x_offset, y_offset), scaled_image)
        
        return result
    
    def apply_style(
        self, 
        image: Image.Image,
            transparent_bg: bool = True,  # ä½¿ç”¨é€æ˜èƒŒæ™¯
            add_outline: bool = False,  # ä¸ä½¿ç”¨ç™½è‰²æé‚Š
        outline_width: int = 8,
        output_size: tuple[int, int] = None,
        normalize_size: bool = True,
        target_size: tuple[int, int] = (1000, 1000)
    ) -> Image.Image:
        """
        å¥—ç”¨é¢¨æ ¼è½‰æ›ï¼ˆå‘é‡æ’ç•«é¢¨æ ¼ï¼ŒåŠå¯«å¯¦ä¼æ¥­é ­åƒã€è³½ç’ç’è‘—è‰²ã€éš¨æ©Ÿé«˜å…‰ã€é€æ˜èƒŒæ™¯ï¼Œèƒ¸éƒ¨ä»¥ä¸Šè£å‰ªï¼Œçµ±ä¸€å°ºå¯¸ï¼‰
        
        Args:
            image: è¼¸å…¥åœ–ç‰‡
            transparent_bg: æ˜¯å¦ä½¿ç”¨é€æ˜èƒŒæ™¯ï¼ˆé è¨­ç‚º Trueï¼Œé€æ˜èƒŒæ™¯ï¼‰
            add_outline: æ˜¯å¦æ·»åŠ ç™½è‰²ç²—ç·šæé‚Šï¼ˆé è¨­ç‚º Falseï¼Œä¸ä½¿ç”¨æé‚Šï¼‰
            outline_width: æé‚Šå¯¬åº¦ï¼ˆåƒç´ ï¼‰
            output_size: è¼¸å‡ºå°ºå¯¸ (width, height)ï¼ŒNone å‰‡ä½¿ç”¨ target_size
            normalize_size: æ˜¯å¦çµ±ä¸€å°ºå¯¸å’Œä½ç½®ï¼ˆå¢åŠ åŒè³ªæ€§ï¼‰
            target_size: ç›®æ¨™çµ±ä¸€å°ºå¯¸ (width, height)
            
        Returns:
            è½‰æ›å¾Œçš„åœ–ç‰‡
            
        Note:
            - å‘é‡æ’ç•«é¢¨æ ¼ï¼ŒåŠå¯«å¯¦ä¼æ¥­é ­åƒ
            - è³½ç’ç’è‘—è‰²ï¼ˆcel-shadedï¼‰ï¼Œç¡¬é™°å½±
            - éš¨æ©Ÿé«˜å…‰æ•ˆæœï¼ˆæ©˜è‰²/é‡‘è‰²é‚Šç·£å…‰ï¼Œéš¨æ©Ÿè§’åº¦ï¼‰
            - é€æ˜èƒŒæ™¯
            - èº«é«”ç”Ÿæˆæ©Ÿåˆ¶ï¼šå¦‚æœåªæœ‰è„–å­ï¼Œç”Ÿæˆåˆ°èƒ¸éƒ¨ï¼›å¦‚æœå…¨èº«ï¼Œåªç”Ÿæˆåˆ°èƒ¸éƒ¨
        """
        # ä½¿ç”¨åˆä½µçš„ API å‘¼å«åŒæ™‚æª¢æ¸¬åœ–ç‰‡é¡å‹å’Œèº«é«”ç¯„åœï¼ˆç¯€çœ 33% API é…é¡ï¼‰
        analysis = self.analyze_image(image)
        image_type = analysis["image_type"]
        body_extent = analysis["body_extent"]
        
        print(f"ğŸ“Š åœ–ç‰‡åˆ†æçµæœ: é¡å‹={image_type}, èº«é«”ç¯„åœ={body_extent}")
        
        if image_type == "illustration":
            # å¦‚æœæ˜¯æ’ç•«/å‘é‡åœ–ï¼Œä¹Ÿé€²è¡Œ AI ç”Ÿæˆè½‰æ›ï¼ˆæ‰€æœ‰åœ–ç‰‡éƒ½è½‰æ›ï¼ŒåŒ…æ‹¬é¸æ“‡æ€§æ©˜è‰²é«˜å…‰ï¼‰
            result = self.convert_to_cartoon_illustration(image, body_extent="head_chest")
            
            # è™•ç†é€æ˜èƒŒæ™¯ï¼ˆæ’ç•«/å‘é‡åœ–ä¹Ÿéœ€è¦è™•ç†ï¼‰
            if transparent_bg:
                result = self.make_white_transparent(result)
        else:
            # å¦‚æœæ˜¯çœŸäººç…§ç‰‡ï¼Œæ ¹æ“šèº«é«”éƒ¨ä½ç¯„åœé€²è¡Œè™•ç†
            # è½‰æ›ç‚ºå‘é‡æ’ç•«é¢¨æ ¼ï¼ˆAI æœƒæ ¹æ“š body_extent è‡ªå‹•è™•ç†èº«é«”ç”Ÿæˆå’Œè£å‰ªåˆ°èƒ¸éƒ¨ä»¥ä¸Šï¼ŒåŒ…æ‹¬é¸æ“‡æ€§æ©˜è‰²é«˜å…‰ï¼‰
            result = self.convert_to_cartoon_illustration(image, body_extent=body_extent)
            
            # è™•ç†é€æ˜èƒŒæ™¯
            if transparent_bg:
                result = self.make_white_transparent(result)
        
        # çµ±ä¸€å°ºå¯¸å’Œä½ç½®ï¼ˆå¢åŠ åŒè³ªæ€§ï¼‰
        if normalize_size:
            result = self.normalize_size_and_position(result, target_size=target_size)
            # ä½¿ç”¨çµ±ä¸€çš„è¼¸å‡ºå°ºå¯¸
            if output_size is None:
                output_size = target_size
        
        # ä¸æ·»åŠ ç™½è‰²æé‚Š
        # å°æ–¼çœŸäººç…§ç‰‡ï¼Œé€²è¡Œæ°´å¹³åº•éƒ¨è£åˆ‡
        if image_type == "photo" and normalize_size:
            result = self.crop_horizontal_bottom(result)
        
        return result

